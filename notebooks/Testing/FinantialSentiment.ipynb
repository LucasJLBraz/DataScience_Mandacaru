{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Análise de Sentimento Financeiro com Modelos Profundos"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Índice\n",
    "1. [Carregamento de Dados](##carregamento)\n",
    "2. [Pré-processamento](##pre-processamento)\n",
    "3. [Treinamento do Modelo X](#modelo-x)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T21:40:36.663158Z",
     "start_time": "2025-05-21T21:40:36.003366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import nltk\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Carregamento de Dados"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T21:41:15.348897Z",
     "start_time": "2025-05-21T21:41:15.255816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ler o arquivo CSV\n",
    "df = pd.read_csv(\"./data/data.csv\", names=['data', 'label'])"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Ler o arquivo CSV\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m df = pd.read_csv(\u001B[33m\"\u001B[39m\u001B[33m./data/data.csv\u001B[39m\u001B[33m\"\u001B[39m, names=[\u001B[33m'\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m'\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/DataScience_Mandacaru/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/DataScience_Mandacaru/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = TextFileReader(filepath_or_buffer, **kwds)\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/DataScience_Mandacaru/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28mself\u001B[39m._make_engine(f, \u001B[38;5;28mself\u001B[39m.engine)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/DataScience_Mandacaru/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = get_handle(\n\u001B[32m   1881\u001B[39m     f,\n\u001B[32m   1882\u001B[39m     mode,\n\u001B[32m   1883\u001B[39m     encoding=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[32m   1884\u001B[39m     compression=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mcompression\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[32m   1885\u001B[39m     memory_map=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mmemory_map\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[32m   1886\u001B[39m     is_text=is_text,\n\u001B[32m   1887\u001B[39m     errors=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mencoding_errors\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstrict\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1888\u001B[39m     storage_options=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mstorage_options\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[32m   1889\u001B[39m )\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/DataScience_Mandacaru/lib/python3.12/site-packages/pandas/io/common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(\n\u001B[32m    874\u001B[39m             handle,\n\u001B[32m    875\u001B[39m             ioargs.mode,\n\u001B[32m    876\u001B[39m             encoding=ioargs.encoding,\n\u001B[32m    877\u001B[39m             errors=errors,\n\u001B[32m    878\u001B[39m             newline=\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    879\u001B[39m         )\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: './data/data.csv'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pré-processamento"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Removendo linhas com valores nulos ou vazios"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remover linhas com valores nulos ou vazios\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo a primeira linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T23:41:14.189555138Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remover a primeira linha\n",
    "df = df.iloc[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo alphanumericos, pontuação, stopwords e deixando tudo em minúsculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T23:41:14.190450419Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/apo-pc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/tmp/ipykernel_11864/2354185342.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['data'] = df['data'].str.replace('\\d+', '')\n",
      "/tmp/ipykernel_11864/2354185342.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['data'] = df['data'].str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "# Remover alfanuméricos\n",
    "df['data'] = df['data'].str.replace('\\d+', '')\n",
    "\n",
    "# Deixar tudo em minúsculo\n",
    "df['data'] = df['data'].str.lower()\n",
    "\n",
    "# Remover pontuação\n",
    "df['data'] = df['data'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "# Remover stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "df['data'] = df['data'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T23:41:14.191216779Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/apo-pc/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatização\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['data'] = df['data'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo os dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.053518494Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['data'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.070422751Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2508\n",
       "positive    1480\n",
       "negative     685\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COntar qtd de classes\n",
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificando a variável target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.071360763Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the training labels\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Transform the test labels (use the same label encoder instance)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorização\n",
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.083268269Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pré-processar os dados de texto\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "X_puro_train_tfidf = X_train_tfidf\n",
    "X_puro_test_tfidf = X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "### Importando bibliotecas\n",
    "(Pytorch=LSTM, RNN, CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.089353674Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.130729800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo dispositivo CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.130729800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA é suportado pelo sistema? True\n",
      "Versao do CUDA: 12.1\n",
      "ID do CUDA device: 0\n",
      "Nome do dispositivo CUDA:NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA é suportado pelo sistema? {torch.cuda.is_available()}\")\n",
    "print(f\"Versao do CUDA: {torch.version.cuda}\")\n",
    " \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID do CUDA device: {torch.cuda.current_device()}\")\n",
    "       \n",
    "print(f\"Nome do dispositivo CUDA:{torch.cuda.get_device_name(cuda_id)}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.set_default_device('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.130729800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert text data to PyTorch tensors\n",
    "X_train_tfidf = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32)\n",
    "X_test_tfidf = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and testing data\n",
    "train_dataset = TensorDataset(X_train_tfidf, y_train)\n",
    "test_dataset = TensorDataset(X_test_tfidf, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.131430177Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a simple LSTM model\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add an extra dimension to the input tensor\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        return out\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train_tfidf.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "output_size = len(df['label'].unique())  # Assuming your labels are numerical\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = SimpleLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the LSTM model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tfidf)\n",
    "    _, predicted = torch.max(test_outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.131430177Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.25      0.27       175\n",
      "           1       0.71      0.76      0.74       622\n",
      "           2       0.73      0.71      0.72       372\n",
      "\n",
      "    accuracy                           0.67      1169\n",
      "   macro avg       0.58      0.57      0.58      1169\n",
      "weighted avg       0.66      0.67      0.66      1169\n",
      "\n",
      "Accuracy: 0.6680923866552609\n"
     ]
    }
   ],
   "source": [
    "# Convert the PyTorch tensors back to NumPy arrays for sklearn metrics\n",
    "predicted = predicted.cpu().numpy()\n",
    "y_test = y_test.cpu().numpy()\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.132080402Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [100/147], Loss: 1.0027\n",
      "Epoch [2/10], Batch [100/147], Loss: 0.8041\n",
      "Epoch [3/10], Batch [100/147], Loss: 0.5553\n",
      "Epoch [4/10], Batch [100/147], Loss: 0.3283\n",
      "Epoch [5/10], Batch [100/147], Loss: 0.2272\n",
      "Epoch [6/10], Batch [100/147], Loss: 0.1786\n",
      "Epoch [7/10], Batch [100/147], Loss: 0.1722\n",
      "Epoch [8/10], Batch [100/147], Loss: 0.1692\n",
      "Epoch [9/10], Batch [100/147], Loss: 0.1654\n",
      "Epoch [10/10], Batch [100/147], Loss: 0.1639\n"
     ]
    }
   ],
   "source": [
    "class RobustLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, bidirectional=True, dropout=0.5):\n",
    "        super(RobustLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train_tfidf.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2  # Increased the number of layers\n",
    "output_size = len(df['label'].unique())\n",
    "bidirectional = True\n",
    "dropout = 0.5\n",
    "\n",
    "# Instantiate the model with bidirectional LSTM and dropout\n",
    "model = RobustLSTM(input_size, hidden_size, num_layers, output_size, bidirectional=bidirectional, dropout=dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Implement learning rate scheduling\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# Train the LSTM model with progress updates\n",
    "num_epochs = 10\n",
    "print_interval = 100  # Print loss every 100 batches\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Print training progress\n",
    "        if batch_idx % print_interval == 0 and batch_idx > 0:\n",
    "            avg_loss = total_loss / print_interval\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {avg_loss:.4f}\")\n",
    "            total_loss = 0.0\n",
    "\n",
    "    # Learning rate scheduling step\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.174615273Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.26      0.29       175\n",
      "           1       0.72      0.77      0.74       622\n",
      "           2       0.73      0.70      0.72       372\n",
      "\n",
      "    accuracy                           0.67      1169\n",
      "   macro avg       0.59      0.58      0.58      1169\n",
      "weighted avg       0.66      0.67      0.67      1169\n",
      "\n",
      "Accuracy: 0.6740804106073567\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tfidf)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "\n",
    "# Convert the PyTorch tensors back to NumPy arrays for sklearn metrics\n",
    "predicted = predicted.cpu().numpy()\n",
    "# y_test = y_test.numpy()\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T18:36:30.175132488Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.7066\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6775\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6561\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6655\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6689\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6843\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6655\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6621\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6963\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6775\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6561\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6621\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6544\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6664\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6895\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6681\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6707\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6604\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6664\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6681\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6544\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.5988\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.7032\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6843\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6621\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6775\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6681\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6775\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6424\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.7049\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6724\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6689\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6672\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6612\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6758\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6724\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6732\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6322\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6938\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6561\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6595\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6741\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6689\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6561\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.5381\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6946\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6912\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6775\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6775\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6630\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6578\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6980\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6681\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6185\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.7074\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6843\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6732\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6741\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6570\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6732\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6920\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6826\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6433\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6989\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6724\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6655\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6698\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6484\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6664\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6801\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6356\n",
      "Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.3182\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6972\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6929\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6689\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6681\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6604\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6775\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6707\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6689\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6476\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.7049\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6749\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6826\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6630\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6647\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6749\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6681\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6510\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6963\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6698\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6604\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6792\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6724\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6647\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.3, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6467\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6972\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6946\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6647\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6724\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6595\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6766\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6732\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6869\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.7032\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6784\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6219\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6621\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6826\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6784\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6655\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6997\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6732\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6587\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6681\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6775\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6630\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6681\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.5, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6270\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6604\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6527\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6322\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6724\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6664\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6527\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6826\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6655\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 32, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6450\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.7040\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6869\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6587\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6758\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6536\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6715\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6946\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6689\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6544\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 1}, Accuracy: 0.6997\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 2}, Accuracy: 0.6689\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.001, 'num_layers': 3}, Accuracy: 0.6741\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 1}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 2}, Accuracy: 0.6595\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.01, 'num_layers': 3}, Accuracy: 0.6638\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 1}, Accuracy: 0.6903\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 2}, Accuracy: 0.6792\n",
      "Parameters: {'bidirectional': False, 'dropout': 0.7, 'hidden_size': 128, 'learning_rate': 0.1, 'num_layers': 3}, Accuracy: 0.6715\n",
      "Best Parameters: {'bidirectional': True, 'dropout': 0.7, 'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}\n",
      "Best Accuracy: 0.7074422583404619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Define a grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'hidden_size': [32, 64, 128],\n",
    "    'num_layers': [1, 2, 3],\n",
    "    'bidirectional': [True, False],\n",
    "    'dropout': [0.3, 0.5, 0.7],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_params = None\n",
    "\n",
    "# Perform grid search\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = RobustLSTM(input_size, params['hidden_size'], params['num_layers'],\n",
    "                       output_size, bidirectional=params['bidirectional'], dropout=params['dropout'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tfidf)\n",
    "        _, predicted = torch.max(test_outputs, 1)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predicted.cpu())\n",
    "    print(f\"Parameters: {params}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Update best parameters if the current model is better\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[119], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Convert text data to PyTorch tensors\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m X_train_tfidf \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(X_train_tfidf\u001B[38;5;241m.\u001B[39mtoarray(), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m      3\u001B[0m X_test_tfidf \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(X_test_tfidf\u001B[38;5;241m.\u001B[39mtoarray(), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m      4\u001B[0m y_train \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(y_train, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "# Convert text data to PyTorch tensors\n",
    "X_train_tfidf = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32)\n",
    "X_test_tfidf = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and testing data\n",
    "train_dataset = TensorDataset(X_train_tfidf, y_train)\n",
    "test_dataset = TensorDataset(X_test_tfidf, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple RNN model\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        return out\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train_tfidf.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "output_size = len(torch.unique(y_train))\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = SimpleRNN(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train_tfidf.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "output_size = len(torch.unique(y_train))\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = SimpleRNN(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the RNN model\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Add a sequence dimension to the input\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    train_losses.append(epoch_loss / len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.24      0.27       175\n",
      "           1       0.71      0.76      0.73       622\n",
      "           2       0.72      0.72      0.72       372\n",
      "\n",
      "    accuracy                           0.67      1169\n",
      "   macro avg       0.58      0.57      0.57      1169\n",
      "weighted avg       0.65      0.67      0.66      1169\n",
      "\n",
      "Accuracy: 0.6672369546621043\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss graph\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Add a sequence dimension to the test input\n",
    "    X_test_tfidf = X_test_tfidf.unsqueeze(1)\n",
    "    X_test_tfidf = X_test_tfidf\n",
    "\n",
    "    test_outputs = model(X_test_tfidf)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "\n",
    "\n",
    "# Convert the PyTorch tensors back to NumPy arrays for sklearn metrics\n",
    "predicted = predicted.cpu().numpy()\n",
    "y_test = y_test.cpu().numpy()\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN mais Robusto com GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming you have X_train_tfidf, X_test_tfidf, y_train, and y_test from your previous code\n",
    "\n",
    "# # Convert text data to PyTorch tensors\n",
    "# X_train_tfidf = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32)\n",
    "# X_test_tfidf = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
    "# y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "# y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# # Create DataLoader for training and testing data\n",
    "# train_dataset = TensorDataset(X_train_tfidf, y_train)\n",
    "# test_dataset = TensorDataset(X_test_tfidf, y_test)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define a more robust RNN model\n",
    "class RobustRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_rate=0.0):\n",
    "        super(RobustRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'estimator' parameter of GridSearchCV must be an object implementing 'fit'. Got PyTorchClassifier(\n  (base_model): RobustRNN(\n    (rnn): RNN(8587, 64, batch_first=True)\n    (fc): Linear(in_features=64, out_features=3, bias=True)\n  )\n) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidParameterError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[128], line 70\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# Use GridSearchCV for hyperparameter tuning\u001B[39;00m\n\u001B[1;32m     69\u001B[0m grid_search_model \u001B[38;5;241m=\u001B[39m GridSearchCV(wrapped_model, param_grid, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m---> 70\u001B[0m grid_search_model\u001B[38;5;241m.\u001B[39mfit(X_train_tfidf, y_train)\n\u001B[1;32m     72\u001B[0m \u001B[38;5;66;03m# Get the best model from grid search\u001B[39;00m\n\u001B[1;32m     73\u001B[0m best_model \u001B[38;5;241m=\u001B[39m grid_search_model\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mbase_model\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1144\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1139\u001B[0m partial_fit_and_fitted \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1140\u001B[0m     fit_method\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartial_fit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m _is_fitted(estimator)\n\u001B[1;32m   1141\u001B[0m )\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m global_skip_validation \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m partial_fit_and_fitted:\n\u001B[0;32m-> 1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[1;32m   1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:637\u001B[0m, in \u001B[0;36mBaseEstimator._validate_params\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_params\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    630\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001B[39;00m\n\u001B[1;32m    631\u001B[0m \n\u001B[1;32m    632\u001B[0m \u001B[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;124;03m    accepted constraints.\u001B[39;00m\n\u001B[1;32m    636\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 637\u001B[0m     validate_parameter_constraints(\n\u001B[1;32m    638\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parameter_constraints,\n\u001B[1;32m    639\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_params(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m    640\u001B[0m         caller_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    641\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95\u001B[0m, in \u001B[0;36mvalidate_parameter_constraints\u001B[0;34m(parameter_constraints, params, caller_name)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     90\u001B[0m     constraints_str \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     91\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;28mstr\u001B[39m(c)\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mconstraints[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     92\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstraints[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     93\u001B[0m     )\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m InvalidParameterError(\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam_name\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m parameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcaller_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstraints_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam_val\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     98\u001B[0m )\n",
      "\u001B[0;31mInvalidParameterError\u001B[0m: The 'estimator' parameter of GridSearchCV must be an object implementing 'fit'. Got PyTorchClassifier(\n  (base_model): RobustRNN(\n    (rnn): RNN(8587, 64, batch_first=True)\n    (fc): Linear(in_features=64, out_features=3, bias=True)\n  )\n) instead."
     ]
    }
   ],
   "source": [
    "# Create a function to train and # Convert text data to PyTorch tensors\n",
    "# X_train_tfidf = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32)\n",
    "# X_test_tfidf = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
    "# y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "# y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# # Create DataLoader for training and testing data\n",
    "# train_dataset = TensorDataset(X_train_tfidf, y_train)\n",
    "# test_dataset = TensorDataset(X_test_tfidf, y_test)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)evaluate the model\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        train_losses.append(epoch_train_loss / len(train_loader))\n",
    "\n",
    "        # Validation loss\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_loss = 0.0\n",
    "            for val_inputs, val_labels in test_loader:\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "\n",
    "            val_losses.append(epoch_val_loss / len(test_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]}, Validation Loss: {val_losses[-1]}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Set hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'hidden_size': [32, 64, 128],\n",
    "    'num_layers': [1, 2],\n",
    "    'dropout_rate': [0.0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "base_model = RobustRNN(input_size, hidden_size, num_layers, output_size)\n",
    "base_criterion = nn.CrossEntropyLoss()\n",
    "base_optimizer = optim.Adam(base_model.parameters(), lr=0.001)\n",
    "\n",
    "# Wrap the model for use with GridSearchCV\n",
    "class PyTorchClassifier(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(PyTorchClassifier, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Create PyTorch model wrapper\n",
    "wrapped_model = PyTorchClassifier(base_model)\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search_model = GridSearchCV(wrapped_model, param_grid, cv=3)\n",
    "grid_search_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search_model.best_estimator_.base_model\n",
    "\n",
    "# Train and evaluate the best model\n",
    "best_criterion = nn.CrossEntropyLoss()\n",
    "best_optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = train_and_evaluate(best_model, train_loader, test_loader, best_criterion, best_optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss curves\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(X_test_tfidf)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "\n",
    "# Convert the PyTorch tensors back to NumPy arrays for sklearn metrics\n",
    "predicted = predicted.numpy()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mulher do Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T23:41:52.068767629Z",
     "start_time": "2023-11-21T23:41:51.997490993Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMportando CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_model = CountVectorizer()\n",
    "bow_df = pd.DataFrame(bow_model.fit_transform(df['data']).todense())\n",
    "bow_df.columns = sorted(bow_model.vocabulary_)\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow_df, df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_labels)*100\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[192], line 61\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m     60\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 61\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[1;32m     62\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m     63\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[192], line 34\u001B[0m, in \u001B[0;36mRobustRNN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     33\u001B[0m     out, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlstm(x)\n\u001B[0;32m---> 34\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(out[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :])  \u001B[38;5;66;03m# Take the output from the last time step\u001B[39;00m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_device.py:77\u001B[0m, in \u001B[0;36mDeviceContext.__torch_function__\u001B[0;34m(self, func, types, args, kwargs)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m _device_constructors() \u001B[38;5;129;01mand\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     76\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mIndexError\u001B[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming you have X_train_tfidf, X_test_tfidf, y_train, and y_test from your previous code\n",
    "\n",
    "X_train_tfidf=X_puro_train_tfidf\n",
    "X_test_tfidf=X_puro_test_tfidf\n",
    "\n",
    "# Convert text data to PyTorch tensors\n",
    "X_train_tfidf = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32)\n",
    "X_test_tfidf = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and testing data\n",
    "train_dataset = TensorDataset(X_train_tfidf, y_train)\n",
    "test_dataset = TensorDataset(X_test_tfidf, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define a more robust RNN model with LSTM\n",
    "class RobustRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RobustRNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        return out\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train_tfidf.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2  # Increase the number of layers for a more complex model\n",
    "output_size = len(torch.unique(y_train))\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = RobustRNN(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the RNN model with visualization of training loss and accuracy\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Average loss and accuracy for the epoch\n",
    "    average_loss = epoch_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    # Store the values for visualization\n",
    "    train_losses.append(average_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} => Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot the training loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy', color='orange')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tfidf)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "\n",
    "# Convert the PyTorch tensors back to NumPy arrays for sklearn metrics\n",
    "predicted = predicted.numpy()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
